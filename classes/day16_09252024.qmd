---
title: "Day 16 - 09/25/2024"
format: html
editor: visual
---

## Model diagnostics, or evaluating assumptions

Our statistical models are a simplification of reality.

-   What can we do with data alone?\
-   What can we do with data and a statistical model?\
-   What is a statistical model? (a list of assumptions)\
-   Our assumptions should represent the **data generating process** as good as possible.
    -   Plant density example\
    -   Clover data example\
-   Class poll: Do you really expect our assumptions to be exactly right?

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggpubr)
library(latex2exp)
library(car)
url <- "https://raw.githubusercontent.com/jlacasa/stat705_fall2024/main/classes/data/corn_example2.csv"
dd <- read.csv(url)
```

```{r message=FALSE, warning=FALSE}
dd %>% 
  ggplot(aes(plant_density, yield_Mgha))+
  geom_point()+
  labs(x = expression(Plant~Density~(plants~m^{-2})), 
       y = expression(Grain~Yield~(Mg~ha^{-1})))+
  theme_classic()+
  coord_cartesian(xlim = c(0, 15), 
                  ylim = c(0, 16), 
                  expand = F)+
  theme(aspect.ratio = 1)
```

**Given our prior knowledge about the subject**, we can fit the following model:

$$y_i \sim N(\mu_i, \sigma^2),$$ $$\mu_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2,$$ for $i =1, 2, ..., n$ where $n$ is the total number of observations, $y_i$ is the $i$th observation of grain yield, that arises from a Normal distribution with mean $\mu_i$ and variance $\sigma^2$. The $mu_i$ is defined as a function of the parameters $\beta_0$, $beta_1$ and $\beta_2$, and the predictor $x_i$, plant density.

```{r}
m1 <- lm(yield_Mgha ~ plant_density + I(plant_density^2), data = dd)
m1_residuals <- m1$residuals
summary(m1)
```

#### Recall our Assumptions for all the models we've been fitting so far

-   Linearity\
-   Homoscedasticity (i.e., constant variance)\
-   Residuals are iid $\sim N(0, \sigma^2)$
    -   Independent\
    -   Normally distributed

#### A few things to keep in mind:

-   "All models are wrong, but some are useful" [George E. P. Box](https://en.wikipedia.org/wiki/George_E._P._Box) \[[interview](https://projecteuclid.org/journals/statistical-science/volume-2/issue-3/A-Conversation-with-George-Box/10.1214/ss/1177013223.full)\] \[[book](https://www.amazon.com/Accidental-Statistician-Life-Memories-George/dp/1118400887)\]\
-   If we agree on the fact that no assumption can be right, we wish to assess the degree of violation of our assumptions.\
-   Possible conclusions of the checking assumptions step:
    -   assumptions are not badly violated \~ reliable predictions & inference.\
    -   assumptions are badly violated \~ unreliable predictions & inference \~ change your model!

## Tools for model diagnostics

### Graphical/descriptive methods

-   Pros
    -   Transparency
-   Cons
    -   Need knowledge about statistics, experience, judgment, etc.

#### Linearity/Deterministic Part of the Model

We aim to check whether the deterministic part of the model truly represents the data generating process. This should make sense with our knowledge about the topic.

```{r}
dd %>% 
  ggplot(aes(plant_density, yield_Mgha))+
  geom_point()+
  labs(x = expression(Plant~Density~(plants~m^{-2})), 
       y = expression(Grain~Yield~(Mg~ha^{-1})))+
  theme_classic()+
  coord_cartesian(xlim = c(0, 15), 
                  ylim = c(0, 16), 
                  expand = F)+
  theme(aspect.ratio = 1)
```

```{r}
dd$epsilon.hat <- m1_residuals
dd$y.hat <- m1$fitted.values

dd %>% 
  ggplot(aes(y.hat, epsilon.hat))+
  geom_hline(yintercept = 0, linetype =2)+
  geom_point()+
  labs(x = TeX("$\\hat{y}_i$"), 
       y = TeX("$\\hat{\\epsilon}_i$"))+
  theme_classic()+
  theme(aspect.ratio = 1)
```

#### Homoscedasticity (i.e., constant variance)

We aim to check whether the variance is approximately homogeneous across the different levels of the predictor variable. And especially, whether the heteroscedasticity is **so bad** that we need to change our model.

```{r}
dd %>% 
  ggplot(aes(y.hat, abs(epsilon.hat)))+
  geom_point()+
  labs(x = TeX("$\\hat{y}_i$"), 
       y = TeX("$|\\hat{\\epsilon}_i|$"))+
  theme_classic()+
  theme(aspect.ratio = 1)
```

#### Independent Residuals

For time series:

```{r eval=FALSE}
n <- nrow(dd)
lag_residuals <- c(NA, m1_residuals[1:n-1])

plot(1:n, m1_residuals)

plot(lag_residuals, m1_residuals)
```

#### Residuals are $\sim N(0, \sigma^2)$

**IMPORTANT!!!** Each **conditional distribution** $p(y|x)$ (one for each x) is a normal distribution, not the marginal $p(y)$.

```{r}
hist(m1_residuals)
```

```{r}
qqPlot(m1_residuals)
```

### Testing methods

-   Pros
    -   Very common & popular. Used to be the paradigm a few decades ago (your PI probably loves them!).\
-   Cons
    -   When is *any* assumption true anyways?\
    -   Sensitive to sample size $n$
        -   With lower $n$, it's less likely to reject $H_0$ and say the assumptions are violated, even if the assumptions are badly violated.\
        -   With higher $n$, it's more likely to reject $H_0$ and say the assumptions are violated, even if the assumptions are only slightly violated.

> By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis. \[[ASA's statement on p-values](https://www.tandfonline.com/doi/full/10.1080/00031305.2016.1154108#d1e167)\]

#### Linearity/Deterministic Part of the Model

One available testing method to test linearity is looking at the estimated parameters for the curvature.

```{r}
summary(m1)
```

#### Homoscedasticity (i.e., constant variance)

We use the Glejser test,

```{r}
glejser <- lm(abs(m1_residuals) ~ y.hat, data = dd)
summary(glejser)
```

For categorical predictors, you can also apply the Levene test, using the `leveneTest()` function.

#### Independent Residuals

```{r eval=FALSE}
cor.test(m1_residuals, lag_residuals)
```

#### Residuals are $\sim N(0, \sigma^2)$

In the Shapiro test, the $H_0$ is that the residuals are $\sim N(0, \sigma^2)$.

```{r}
shapiro.test(m1_residuals)
```

## For next class

-   Resubmit Assignment 2.
